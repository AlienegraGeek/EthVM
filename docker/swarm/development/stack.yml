version: '3.6'

networks:

  traefik:
    external: true

  backend:
    external: true

volumes:

  traefik:
    external: true

  zookeeper-1:
    external: true
  zookeeper-2:
    external: true
  zookeeper-3:
    external: true

  kafka-1:
    external: true
  kafka-2:
    external: true
  kafka-3:
    external: true

  kafka-streams:
    external: true

  kafka-connect:
    external: true

  mongodb:
    external: true

  parity:
    external: true

services:

  traefik:
    image: enkryptio/traefik:0.1.2
    networks:
      - back
      - traefik
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - traefik:/var/lib/traefik
    ports:
      - 80
      - 443
      - 8080
    environment:
      DEBUG: false
      LOG_LEVEL: INFO
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 6G
        reservations:
          cpus: '2.0'
          memory: 4G
      placement:
        constraints:
          - node.role == manager
      replicas: 1
      restart_policy:
        condition: on-failure

  explorer:
    image: enkryptio/explorer:0.1.0-development
    networks:
      - traefik
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
      placement:
        constraints:
          - node.role == worker
      replicas: 1
      restart_policy:
        condition: on-failure
    labels:
      - 'traefik.enable=true'
      - "traefik.docker.network=traefik"
      - 'traefik.default.protocol=http'
      - 'traefik.frontend.rule=Host:ropsten.ethvm.com'
      - 'traefik.frontend.headers.customResponseHeaders=Access-Control-Allow-Origin:*||Access-Control-Allow-Credentials:true'
      - 'traefik.frontend.passHostHeader=true'
      - 'traefik.backend=explorer'
      - 'traefik.port=80'

  api:
    image: enkryptio/api:0.1.0
    depends_on:
      - mongodb
    networks:
      - backend
      - traefik
    environment:
      ETHVM_MONGO_DB_URL: "mongodb://mongodb:27017/ethvm_dev?w=1&journal=true&maxIdleTimeMS=60000"
      ETHVM_MONGO_DB_NAME: ethvm_dev
      NODE_ENV: development
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 6G
        reservations:
          cpus: '2.0'
          memory: 4G
      placement:
        constraints:
          - node.role == worker
      replicas: 1
      restart_policy:
        condition: on-failure
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=traefik"
      - "traefik.default.protocol=http"
      - "traefik.frontend.rule=Host:api.ropsten.ethvm.com"
      - "traefik.frontend.headers.customResponseHeaders=Access-Control-Allow-Origin:https://ropsten.ethvm.com||Access-Control-Allow-Credentials:true"
      - "traefik.frontend.passHostHeader=true"
      - "traefik.backend=api"
      - "traefik.port=3000"

  mongodb:
    image: enkryptio/mongodb-dev:4.0.5.2
    volumes:
      - mongodb:/data/db
    networks:
      - backend
    environment:
      MONGO_WIRED_TIGER_CACHE_SIZE: 16
    deploy:
      resources:
        limits:
          cpus: '5.0'
          memory: 10G
        reservations:
          cpus: '4.0'
          memory: 8G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == store
      replicas: 1
      restart_policy:
        condition: on-failure

  zookeeper-1:
    image: confluentinc/cp-zookeeper:5.0.1
    volumes:
      - zookeeper-1:/var/lib/zookeeper
    networks:
      - backend
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: "server.1=zookeeper-1:2888:3888 server.2=zookeeper-2:2888:3888 server.3=zookeeper-3:2888:3888"
      ZOOKEEPER_CLIENT_PORT: 2181
    deploy:
      # resources:
      #   limits:
      #     cpus: '2.0'
      #     memory: 4G
      #   reservations:
      #     cpus: '1.0'
      #     memory: 2G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-1
      replicas: 1
      restart_policy:
        condition: on-failure

  zookeeper-2:
    image: confluentinc/cp-zookeeper:5.0.1
    volumes:
      - zookeeper-2:/var/lib/zookeeper
    networks:
      - backend
    environment:
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_SERVERS: "server.1=zookeeper-1:2888:3888 server.2=zookeeper-2:2888:3888 server.3=zookeeper-3:2888:3888"
      ZOOKEEPER_CLIENT_PORT: 2181
    deploy:
      # resources:
      #   limits:
      #     cpus: '2.0'
      #     memory: 4G
      #   reservations:
      #     cpus: '1.0'
      #     memory: 2G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-2
      replicas: 1
      restart_policy:
        condition: on-failure

  zookeeper-3:
    image: confluentinc/cp-zookeeper:5.0.1
    volumes:
      - zookeeper-3:/var/lib/zookeeper
    networks:
      - backend
    environment:
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_SERVERS: "server.1=zookeeper-1:2888:3888 server.2=zookeeper-2:2888:3888 server.3=zookeeper-3:2888:3888"
      ZOOKEEPER_CLIENT_PORT: 2181
    deploy:
      # resources:
      #   limits:
      #     cpus: '2.0'
      #     memory: 4G
      #   reservations:
      #     cpus: '1.0'
      #     memory: 2G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-3
      replicas: 1
      restart_policy:
        condition: on-failure

  kafka-1:
    image: confluentinc/cp-kafka:5.0.1
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    networks:
      - backend
    ports:
      - target: 9094
        published: 9094
        protocol: tcp
        mode: host
    volumes:
      - kafka:/var/lib/kafka
    environment:
      HOSTNAME_COMMAND: "docker info | grep ^Name: | cut -d' ' -f 2"
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://_{HOSTNAME_COMMAND}:9094
      KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE://:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181,zookeeper-2:2181,zookeeper-3:2181
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CONFLUENT_SUPPORT_METRICS_ENABLE: "true"
      KAFKA_MESSAGE_MAX_BYTES: 52428800
      KAFKA_REPLICA_FETCH_MAX_BYTES: 52428800
      KAFKA_PRODUCER_MAX_REQUEST_SIZE: 5048576
      KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES: 52428800
      KAFKA_JMX_PORT: 9586
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '3.0'
          memory: 4G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-1
      replicas: 1
      restart_policy:
        condition: on-failure

  kafka-2:
    image: confluentinc/cp-kafka:5.0.1
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    networks:
      - backend
    volumes:
      - kafka:/var/lib/kafka
    environment:
      KAFKA_ADVERTISED_HOST_NAME: "kafka-2"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-2:9092"
      KAFKA_ZOOKEEPER_CONNECT:
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_MESSAGE_MAX_BYTES: "2000000000"
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '3.0'
          memory: 4G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-2
      replicas: 1
      restart_policy:
        condition: on-failure

  kafka-3:
    image: confluentinc/cp-kafka:5.0.1
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
    networks:
      - backend
    volumes:
      - kafka:/var/lib/kafka
    environment:
      KAFKA_ADVERTISED_HOST_NAME: "kafka-3"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-3:9092"
      KAFKA_ZOOKEEPER_CONNECT:
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_MESSAGE_MAX_BYTES: "2000000000"
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '3.0'
          memory: 4G
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType == processing-3
      replicas: 1
      restart_policy:
        condition: on-failure

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:5.0.1
    depends_on:
      - zookeeper
      - kafka
    networks:
      - backend
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka-1:9091"
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: "INFO"
      SCHEMA_REGISTRY_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '1.0'
          memory: 512M
      placement:
        constraints:
          - node.role == worker
          - node.labels.io.ethvm.nodeType != processing-1
          - node.labels.io.ethvm.nodeType != processing-2
          - node.labels.io.ethvm.nodeType != processing-3
      replicas: 1
      restart_policy:
        condition: on-failure

  kafka-streams:
    image: enkryptio/kafka-streams:0.3.0
    depends_on:
      - kafka
      - zookeeper
      - kafka-schema-registry
    networks:
      - backend
    volumes:
      - kafka-streams:/var/lib/kafka-streams
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka-1:9091
      KAFKA_SCHEMA_REGISTRY_URL:
      KAFKA_STREAMS_STATE_DIR: /var/lib/kafka-streams
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
      placement:
        constraints:
          - node.role == worker
      replicas: 0
      restart_policy:
        condition: on-failure

  kafka-connect:
    image: enkryptio/kafka-connect:0.3.0
    restart: unless-stopped
    depends_on:
      - zookeeper-1
      - zookeeper-2
      - zookeeper-3
      - kafka-1
      - kafka-2
      - kafka-3
      - mongodb
      - kafka-schema-registry
    networks:
      - backend
    volumes:
      - kafka-connect:/var/lib/kafka
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka-1:9091
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "ethvm-kafka-connect"
      CONNECT_STATUS_STORAGE_TOPIC: "ethvm-storage-topic"
      CONNECT_CONFIG_STORAGE_TOPIC: "ethvm-storage-config"
      CONNECT_OFFSET_STORAGE_TOPIC: "ethvm-storage-offsets"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_COMMIT_INTERVAL_MS: 1000
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081
      CONNECT_KEY_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR,io.enkrypt.kafka.connect=INFO,org.web3j.protocol.websocket.WebSocketService=WARN"
      KAFKA_JMX_PORT: 9588
      KAFKA_HEAP_OPTS: "-Xms8G -Xmx10G -server"
      CONNECT_KAFKA_HEAP_OPTS: "-Xms8G -Xmx10G -server"
      CONNECT_MAX_REQUEST_SIZE: 52428800
      CONNECT_PRODUCER_MAX_REQUEST_SIZE: 52428800
      CONNECT_CONSUMER_MAX_PARTITION_FETCH_BYTES: 52428800
      KAFKA_MAX_REQUEST_SIZE: 52428800
      KAFKA_PRODUCER_MAX_REQUEST_SIZE: 52428800
      KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES: 52428800
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components,/usr/share/enkryptio
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: G
        reservations:
          cpus: '3.0'
          memory: 10G
      placement:
        constraints:
          - node.role == worker
      replicas: 1
      restart_policy:
        condition: on-failure
